{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, grangercausalitytests\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "data = sm.datasets.macrodata.load_pandas().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам представлены квартальные макроэкономические данные США. В датасете представлен ВВП, его компоненты (совокупный доход, потребление и инвестиции), а также прочие показатели. Задача - спрогнозировать ВВП Америки на 8 кварталов вперёд. Метрика - MAPE. Все гипотезы тестируются на уровне значимости 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка и визуализация. (0.5 балла)\n",
    "\n",
    "Приведите в порядок переменную, отвечающую за время и преобразуйте её в формат pandas datetime с квартальной периодичностью. Визуализируйте ряд ВВП, его автокорреляции и частные автокорреляции. Какие характерные паттерны вы наблюдаете?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ༼ つ ◕_◕ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогноз на основе эндогенной информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение порядка интеграции (1 балл)\n",
    "\n",
    "Определите порядок интеграции ряда ВВП с помощью формальных тестов. В случае противоречий ADF и KPSS-теста, полагайтесь на KPSS-тест. За неправильную спецификацию функциональной формы вспомогательной регрессии для тестов оценка может быть снижена.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ༼ つ ◕_◕ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA-модель (2 балла)\n",
    "\n",
    "Для ряда ВВП подберите оптимальную ARIMA-модель согласно алгоритму с семинара. Для моделей-кандидатов определите максимальные порядки p и q исходя из коррелограмм, и отберите оптимальную модель из всех возможных комбинаций этих параметров. Можно не отбирать модели по AIC, а смотреть только на вневыборочное качество прогноза. Однако советую из любопытства всё же проверить, совпадут ли результаты отбора по информационным критериям и по вневыборочной точности.\n",
    "\n",
    "Для отбора по качеству прогноза используйте любой из двух алгоритмов кросс-валидации и стратегию рекурсивного прогнозирования (она реализована по дефолту в statsmodels). Нужный класс уже импортирован в шапке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ༼ つ ◕_◕ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прогнозы на основе экзогенных факторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест причинности Гранжера (0.5 балла)\n",
    "\n",
    "Постройте модель с распределёнными лагами для прогноза на один шаг вперёд. Для этого выберите одну из переменных, которую будете использовать в качестве регрессора. Кратко поясните свой выбор. Проверьте своё предположение, проведя тест причинности Гранжера. Тест импортирован в шапке. Количество лагов вспомогательной модели установите равным 8.\n",
    "\n",
    "Обратите внимание, что для верного вывода необходимо провести тест в обе стороны, о чём было рассказано на семинаре. Внимательно прочитайте порядок подаваемых на вход переменных в документации теста. Не спорю, что документация statsmodels это нечто кошмарное, но на безрыбье и statsmodels нормальный пакет.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ༼ つ ◕_◕ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель с распределёнными лагами (0.5 балла)\n",
    "\n",
    "Для начала, оцените модель с распределёнными лагами для прогноза на один шаг. Для построения модели используйте последние 8 кварталов. Обратите внимание, что регрессировать нужно как минимум на первый лаг регрессора, а не на нулевой. В противном случае банально не получится построить прогноз. Для оценки модели используйте стандартную линейную регрессию. Можно использовать как реализацию из statsmodels, так и из любого другого адекватного пакета (например, sklearn).\n",
    "\n",
    "Спецификация модели с распределёнными лагами:\n",
    "\n",
    "$y_t = \\beta_0 + \\beta_1 x_{t-1} + ... + \\beta_8 x_{t-8} + \\epsilon_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ༼ つ ◕_◕ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель полиномиальных лагов (2 балла)\n",
    "\n",
    "Постройте модель с полиномиальными лагами на основе предыдущей модели. Спецификация подробно описана в учебнике Магнуса, Катышева и Пересецкого на страницах 266-267 главы 11, учебник есть в чате. Попытайтесь подобрать модель с минимальной степенью полинома, для которой модель с ограничениями будет адекватной согласно F-тесту, либо покажите, что для любая степень полинома меньше 8 не удовлетворяет F-тесту. Тестовая статистика описана на тех же страницах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ༼ つ ◕_◕ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогнозирование (1 балл)\n",
    "\n",
    "\n",
    "На основе результатов предыдущего теста, определите наиболее адекватную модель из двух - либо исходную, либо полиномиальную с некоторым r. Для выбранной модели постройте прогноз с помощью прямой стратегии. Каждая модель будет иметь свои параметры и должна генерировать только одну точку прогноза (итого 8 моделей). Визуально проверьте остатки каждой модели на наличие коинтеграции. Если остатки выглядят стационарными, то это очень хорошо. Значит есть коинтеграция и всё в порядке. Если нет, читай абзац ниже.\n",
    "\n",
    "Скорее всего условие коинтеграции не будет выполнено, особенно если регрессором будет переменная I(2). Вопрос о том, как решать подобные проблемы лежит уже за рамками нашего курса в области многомерного анализа и векторных моделей. Одним из выходов в данном случае будет сделать регрессор стационарным путём взятия разностей, а прогнозируемую переменную оставить в исходных величинах, а после уже регрессировать. А ещё лучше, построить не регрессию, а какую-нибудь UCM-модель, которые вы пройдёте далее. Но опять же, в этой домашке этого делать не надо, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ༼ つ ◕_◕ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Комбинированный метод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADL-модель (2 балла)\n",
    "\n",
    "Предлагается попытаться объединить два вышеописанных метода. На семинаре мы обсуждали, что прогнозировать прямым или рекурсивным методом ARIMAX-модель напрямую может быть проблемно, так как придётся либо выписывать специфические правдобия, либо подставлять для экзогенных переменных прогнозы. Поэтому для того, чтобы объединить учёт эндогенной и экзогенной информации, предлагается оценивать ADL-модели. Такие модели уже можно оценивать МНК, т.е. банально оценивать линейную регрессию как в предыдущем пункте. \n",
    "\n",
    "Для прогнозирования используйте прямую стратегию. Для каждой точки прогноза предназначена своя отдельная модель, как и ранее. На всякий случай выпишу уравнения, которые необходимо оценить:\n",
    "\n",
    "$y_t = \\beta_0 + \\beta_1 y_{t-1} + ... +\\beta_p y_{t-p} + \\gamma_1 x_{t-1} + ... + \\gamma_f x_{t-f} + \\epsilon_t$\n",
    "\n",
    "$y_{t+1} = \\beta_0 + \\beta_1 y_{t-1} + ... +\\beta_p y_{t-p} + \\gamma_1 x_{t-1} + ... + \\gamma_f x_{t-f} + \\epsilon_t$\n",
    "\n",
    "...\n",
    "\n",
    "$y_{t+7} = \\beta_0 + \\beta_1 y_{t-1} + ... +\\beta_p y_{t-p} + \\gamma_1 x_{t-1} + ... + \\gamma_f x_{t-f} + \\epsilon_t$\n",
    "\n",
    "Параметры p и f подберите на основе вневыборочной ошибки прогноза на кросс-валидации. Определите для себя какие-нибудь небольшие p и f (не более 5).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ༼ つ ◕_◕ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация прогнозов (0.5 балла)\n",
    "\n",
    "Красиво визуализируйте на последнем окне кросс-валидации прогнозы всех трёх моделей (эндогенной, экзогенной и комбинированной) и истинных значений ряда. Какая модель оказалась более точной?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ༼ つ ◕_◕ ༽つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мемы (Респект семинариста и ассистента)\n",
    "\n",
    "Скиньте мем. Желательно смешной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ༼ つ ◕_◕ ༽つ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
